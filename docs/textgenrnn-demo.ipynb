{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textgenrnn Demo\n",
    "\n",
    "by [Max Woolf](http://minimaxir.com)\n",
    "\n",
    "*Max's open-source projects are supported by his [Patreon](https://www.patreon.com/minimaxir). If you found this project helpful, any monetary contributions to the Patreon are appreciated and will be put to good creative use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "textgenrnn is a Python module on top of Keras/TensorFlow which can easily generate text using a pretrained recurrent neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `textgenrnn` initializer builds a normal Keras model using pretrained weights, and can be accessed using the `.model` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 40, 100)           39400     \n",
      "_________________________________________________________________\n",
      "rnn (LSTM)                   (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 394)               50826     \n",
      "=================================================================\n",
      "Total params: 207,474\n",
      "Trainable params: 207,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.23029184,  0.38873768,  1.44243455, ...,  0.02188325,\n",
       "         0.99988806,  0.39534315],\n",
       "       [ 0.27457139,  0.11113448,  0.69836587, ...,  0.00198267,\n",
       "         0.53896862, -0.66469818],\n",
       "       [-0.65583014, -0.23063584, -0.02954858, ..., -0.57810479,\n",
       "        -0.49945328,  0.42347968],\n",
       "       ..., \n",
       "       [-0.6520772 ,  0.41390169,  0.23095672, ...,  0.0979294 ,\n",
       "        -0.61514562,  0.13473527],\n",
       "       [ 0.44749245, -0.63437164,  0.22126687, ...,  0.76558161,\n",
       "        -0.46554166,  0.67520618],\n",
       "       [-0.42069891, -0.21347174, -0.50736147, ..., -0.07925921,\n",
       "         0.59502763,  0.20731732]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgen.model.summary()\n",
    "textgen.model.get_layer('rnn').get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text\n",
    "\n",
    "The `generate` function generates `n` text documents and print them to console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president is a protest to the star states and was a beautiful president by a star the comments of the states for the first time to start the street and do you have a look at the first time to st\n",
      "\n",
      "The first thing and the first time to be a starts and the country of the comments in the man and the street to the complete and the star started on the first time to be a president and the star to t\n",
      "\n",
      "The best players that the states and the street to the world and the sign that the straight of the story of the star for the company and the country with the star was a train to the protect the firs\n",
      "\n",
      "The most and a president says the same started to the star star the world and a star to the best of the sunders and the most production of the first time to see the first time to a heart to the stat\n",
      "\n",
      "What is the state of the first time to the best of the state of the states at the state to the stream in the star world in the super in the series with a starts and the first time to the season of t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can set the `temperature` to modify the amount of creativity (default 0.2; I do not recommend setting to more than 1.0), set a `prefix` to force the document to start with certain characters and generate characters accordingly, and set a `return_as_list` flag (default False) to use the generated texts elsewhere in your application (e.g. as an API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump emotional show at the one of the Canada to the special barry after me and what is some destroyed for the week.', \"Trump launches to one cars and a new house to started a star first picture and a friend was a time to wast the months like the show of the conference and season and won't just a provide you read som\", 'Trump More Princess explains to do every ben of the increase and the special explore to be the best with the accurate into reminder of the bag has not the first back people can thank your of the wor', 'Trump is the morning today: http://abcn.ws/2uuuzyy', \"Trump is the sublic companies in the way to a big show in the president in a very asked at the president to show the sign of the country's War The Game of Cancert and Facebook and she shoulder to th\"]\n"
     ]
    }
   ],
   "source": [
    "generated_texts = textgen.generate(n=5, prefix=\"Trump\", temperature=0.5, return_as_list=True)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also `generate_to_file()` to make the generated texts easier to copy/paste to other sources (e.g. blog/social media):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textgen.generate_to_file('textgenrnn_texts.txt', n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on New Text\n",
    "\n",
    "As shown above, the results on the pretrained model vary greatly, since it's a lot of data compressed in a small form. The `train_on_texts` function fine-tunes the model on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['Never gonna give you up, never gonna let you down',\n",
    "            'Never gonna run around and desert you',\n",
    "            'Never gonna make you cry, never gonna say goodbye',\n",
    "            'Never gonna tell a lie and hurt you']\n",
    "\n",
    "textgen.train_on_texts(texts, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the network was only trained on 4 texts, the original network still transfers the latent knowledge of all modern grammar and can incorporate that knowledge into generated texts, which becomes evident at higher temperatures or when using a prefix containign a character not present in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Normal Output\n",
      "---\n",
      "Never gonna give you up, never gonna let you down\n",
      "\n",
      "Never gonna run around and desert you\n",
      "\n",
      "Never gonna give you up, never gonna let you down\n",
      "\n",
      "Never gonna give you up, never gonna let you down\n",
      "\n",
      "Never gonna give you up, never gonna let you down\n",
      "\n",
      "---\n",
      "High Temperature Output\n",
      "---\n",
      "Never gonna gen, say never gun goodbye\n",
      "\n",
      "Never gonna say goodbye\n",
      "\n",
      "20M Prau, never gonna say yes murt that give up, never gonna gooded sought, nove, never gonna give you around and desert you\n",
      "\n",
      "Never gonna give up to chywean and hurt you!\n",
      "\n",
      "super a lie and hurt you\n",
      "\n",
      "---\n",
      "Prefix Output\n",
      "---\n",
      "Xbox Never gonna let you down\n",
      "\n",
      "Xbox Never gonna let you down\n",
      "\n",
      "Xbox Never gonna let you down\n",
      "\n",
      "X Never gonna let you down\n",
      "\n",
      "X Never gonna give you up, never gonna let you down\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"---\\nNormal Output\\n---\")\n",
    "textgen.generate(5)\n",
    "print(\"---\\nHigh Temperature Output\\n---\")\n",
    "textgen.generate(5, temperature=1.0)\n",
    "print(\"---\\nPrefix Output\\n---\")\n",
    "textgen.generate(5, prefix=\"X\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reset a trained model back to the original state by calling `reset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textgen.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in the repository is a `hacker-news-top-2000.txt` file containing a list of the Top 2000 [Hacker News](https://news.ycombinator.com/news) submissions by score. Let's retrain the model using that dataset.\n",
    "\n",
    "For this example, I only will use a single epoch to demonstrate how easily the model learns with just one pass of the data: I recommend leaving the default of 50 epochs, or set it even higher for complex datasets. On my 2016 15\" MacBook Pro (quad-core Skylake CPU), the dataset trains at about 2 minutes per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 texts collected.\n",
      "Epoch 1/1\n",
      "83501/83501 [==============================] - 130s - loss: 1.9109   \n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('../datasets/hacker_news_2000.txt', num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create very distinctly-HN titles, even with the very little amount of training, thanks to the pre-trained nature of the textgenrnn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A SELL to the Sixt Startup Startup\n",
      "\n",
      "Show HN: I did the define the startup from the Bitcoin and I did the startup of the new backdops to the startup\n",
      "\n",
      "Announcing Statement to Programming to Programming Startup Startup\n",
      "\n",
      "My startup to the security the startup from the passed and the startup from the passent from the rest of source of the passenger of the interview\n",
      "\n",
      "A developer of the new to the passenger in the developer of the passing the passed to the back of the privation from the private to be and in the control and and the developer of the back of the str\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Second Story Startup Announcing Arcon-official Machait SpaceX Antillable Statement\n",
      "\n",
      "Apple Startup of Microsoft to Story Hacker to Be Android Startup\n",
      "\n",
      "Apple the Startup to Programming State Startup to Developer in Antillary to Internet State Startup\n",
      "\n",
      "Apple Startup Server Company Is Antile State Startup\n",
      "\n",
      "Apple to the Startup Statement Startup to Be Startup\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5, prefix=\"Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load the Model\n",
    "\n",
    "Saving the weights is supery easy; just call `save()` and give a HDF5 filename. Those weights can then be loaded into a new textgenrnn model by specifying a path to the weights on construction. (Or use `load()` for an existing textgenrnn object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Developer Startup Startup and Programming State Startup\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.save('hn_weights.hdf5')\n",
    "\n",
    "textgen_2 = textgenrnn('hn_weights.hdf5')\n",
    "textgen_2.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ..., \n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgen.model.get_layer('rnn').get_weights()[0] == textgen_2.model.get_layer('rnn').get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the weights between the original model and the new model are equivalent.\n",
    "\n",
    "You can use this functionality to load models from others which have been trained on larger datasets with many more epochs (and the model weights are small enough to fit in an email!). Here's what happens when you generate text from the same 2,000 Hacker News submissions, but trained for 500 epochs on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show HN: My super projects at my startup\n",
      "\n",
      "How to start a linux project\n",
      "\n",
      "Show HN: My mode to care\n",
      "\n",
      "Ask HN: What is it?\n",
      "\n",
      "A Starts Science [pdf]\n",
      "\n",
      "A story about &lt;input\n",
      "\n",
      "The Sixth Stage of Airbnofow You Deep to Tecreracting Seve Has Hells\n",
      "\n",
      "A Startup: Server Aadshaskly 1.0. 198B, Easide choost projects\n",
      "\n",
      "An Ads Audio to Build Apple, I'm Sources Agbertial frerets\n",
      "\n",
      "A Stock About to I want thinking real in the world are commit manager on the investigation interviewidgh of personal priming server says open source of a stringer books on this security issuess\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen_2.load('../weights/hacker_news.hdf5')\n",
    "\n",
    "textgen_2.generate(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2017 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
